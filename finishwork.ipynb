{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"finishwork.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"RGJwqVkWIsfC","colab_type":"code","colab":{}},"source":["cd /content/drive/Shared drives/masterWork/BabyCrying/data"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SdRc3dVidBaF","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"t3M2WMAd3SXf","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4RoDA-dd_tS3","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HzSkvRxe6i1V","colab_type":"code","colab":{}},"source":["\"\"\"\n","这个脚本我们副样本的视频 \n","\"\"\"\n","\n","import os\n","import re\n","import subprocess\n","import random\n","\n","INPUT_VIDEO = \"./UCF-101/\"\n","OUTPUT_FILE = \"./3DCNN/other/\"\n","def replcaeFileName(pic_path):#修改pic_path路径下的文件名\n","  picdirs = os.listdir(pic_path)\n","  j = 0\n","  for picdir in  picdirs:\n","    \n","    picdir = INPUT_VIDEO+picdir+'/'\n","    print(picdir)\n","    piclist=os.listdir(picdir)\n","    total_num=len(piclist)\n","    piclist50 = random.sample(piclist, 65)\n","    print(len(piclist50))\n","    \n","\n","    i=0\n","    for pic in piclist50:\n","        #pic = random.sample(pic, 3000)\n","        if pic.endswith(\".avi\"):#修改成你自己想要重命名的文件格式\n","          old_path=picdir+pic\n","\n","          new_path=OUTPUT_FILE+str(1000+(int(j)))+'.avi' \n","\n","          if os.path.isfile(new_path) is True:\n","            os.remove(new_path)       \n","          print(old_path)\n","          print(new_path)\n","          #cmd = \"ffmpeg -i \" + old_path + \" -ab 160k -ac 2 -ar 44100 -vn \" + new_path\n","          cmd = \"ffmpeg -ss 00:00:00 -i \"+ old_path +\" -t 4 -c copy  \"+new_path\n","          #print(cmd)\n","          subprocess.call(cmd, shell=True)\n","          j = j+1\n","\n","          i=i+1\n","\n","\n","\n","if __name__ == '__main__':\n","   \n","  replcaeFileName(INPUT_VIDEO)\n","\n","\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"39LqFJTwWOGL","colab_type":"code","colab":{}},"source":["\"\"\"\n","d这个代码是将一个文件夹里视频信号。原封不动的转换为音频信号之后，我们再根据这个音频信号却返回另外一个空间查找。没有转换成音频信号的那些文件，并把它们删掉。\n","\"\"\"\n","\n","import os\n","import re\n","import subprocess\n","import random\n","\n","INPUT_VIDEO = \"./3DCNN/other/\"\n","OUTPUT_FILE = \"./SVM/otherwav/\"\n","def replcaeFileName(pic_path):#修改pic_path路径下的文件名\n","    piclist=os.listdir(pic_path)\n","    total_num=len(piclist)\n","    piclist = random.sample(piclist,5000)\n","    print(piclist)\n","    i=0\n","    for pic in piclist:\n","        if pic.endswith(\".avi\"):#修改成你自己想要重命名的文件格式\n","          old_path=INPUT_VIDEO+pic\n","          str1 = pic[0:4]\n","          \n","          new_path=OUTPUT_FILE+str1+'.wav' \n","\n","          if os.path.isfile(new_path) is True:\n","            os.remove(new_path)      \n","\n","          print(new_path)\n","          #cmd = \"ffmpeg -i \" + old_path + \" -ab 160k -ac 2 -ar 44100 -vn \" + new_path\n","          cmd = \"ffmpeg -i \"+ old_path +\" -ac 1 -ar 8000 \"+new_path\n","          subprocess.call(cmd, shell=True)\n","          i= i+1\n","          print(i)\n","          \n","          \n","\n","          i=i+1\n","      \n","          \n","\n","\n","\n","if __name__ == '__main__':\n","   \n","  replcaeFileName(INPUT_VIDEO)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YFOCsq4cXllm","colab_type":"code","colab":{}},"source":["#这个脚本是用来查看某个文件夹里面有多少个文件\n","#3529+1871   5398 -3529=1879\n","import os\n","DIR = './3DCNN/other/'\n","print(len([name for name in os.listdir(DIR) if os.path.isfile(os.path.join(DIR, name))])) "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ONGLCETRgpDM","colab_type":"code","colab":{}},"source":["#!/usr/bin/env python\n","#!这个程序是用来删除某个文件夹内固定大小的文件。\n","import os\n"," \n","def file_path(path):\n","    for (root, dirs, files) in os.walk(path):\n","        for dirc in dirs:\n","            if dirc == 'otherwav':  #更改成你的目录名字\n","                pic_path = os.path.join(root, dirc)\n","                for file in os.listdir(pic_path):\n","                    file = pic_path + '/' + file\n","                    print(file)\n","                    del_small_file(file)\n"," \n"," \n","def del_small_file(file_name):\n","    size = os.path.getsize(file_name)\n","    file_size = 62*1024  #更改成你想删除的界限，我这里是100kb\n","    if size < file_size:\n","        print('remove',size,file_name)\n","        os.remove(file_name)\n"," \n","if __name__ == '__main__':\n","    path = './SVM/'  #更改成你的目录上一级\n","    file_path(path)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3UNDXDDbg6sU","colab_type":"code","colab":{}},"source":["\"\"\"\n","d这个代码是将一个文件夹里视频信号。原封不动的转换为音频信号之后，我们再根据这个音频信号却返回另外一个空间查找。没有转换成音频信号的那些文件，并把它们删掉。\n","\"\"\"\n","\n","import os\n","import re\n","import subprocess\n","\n","INPUT_VIDEO =  \"./3DCNN/other/\"\n","OUTPUT_FILE = \"./SVM/otherwav/\"\n","\n","\n","def replcaeFileName(pic_path):#修改pic_path路径下的文件名\n","    piclist=os.listdir(pic_path)\n","    total_num=len(piclist)\n","    i=0\n","    for pic in piclist:\n","        if pic.endswith(\".avi\"):#修改成你自己想要重命名的文件格式\n","          old_path=INPUT_VIDEO+pic\n","          str1 = pic[0:4]\n","          \n","          new_path=OUTPUT_FILE+str1+'.wav' \n","\n","          if os.path.isfile(new_path) is False:\n","            print(old_path)\n","            os.remove(old_path)  \n","            i = i+1    \n","            print(i)\n","         \n","\n","          \n","          \n","\n","         \n","      \n","          \n","\n","\n","\n","if __name__ == '__main__':\n","   \n","  replcaeFileName(INPUT_VIDEO)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"otV5Kyk46vDo","colab_type":"code","colab":{}},"source":["### 提取语谱图\n","\n","\n","\n","\"\"\"\n","    此模块是提取gram\n","    \n","\"\"\"\n","\n","from scipy import signal\n","\n","\n","from sklearn.metrics import classification_report\n","\n","\n","\n","import os\n","import librosa\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.svm import SVC\n","\n","\n","\n","\n","DATA = 'datagram3s.npy'\n","TARGET = 'targetgram3s.npy'\n","\n","\n","# 加载标签\n","def load_label(label_path):\n","  label = os.listdir(label_path)\n","  return label\n","\n","def wav2melgraf(path):\n","  m_bands = 128\n","  s_rate = 8000\n","  win_length = int(0.1 * s_rate)  # Window length 15ms, 25ms, 50ms, 100ms, 200ms\n","  hop_length = int(0.01 * s_rate)  # Window shift  10ms\n","  n_fft = win_length\n","  y, sr = librosa.load(path, sr=8000)\n","  #进行傅里叶变换\n","  D = np.abs(librosa.stft(y, n_fft=n_fft, win_length=win_length, hop_length=hop_length,\n","                                window=signal.hamming, center=False)) ** 2\n","    #提取特征\n","  S = librosa.feature.melspectrogram(S=D, n_mels=m_bands)\n","  gram = librosa.power_to_db(S, ref=np.max)\n","  gram = np.transpose(gram, (1, 0))\n","  print(gram.shape)\n","  gram = gram[:300,:128]\n","\n","  if gram.shape[0] != 300 or gram.shape[1] != 128 :\n","    print(\"eror:!!!!\",path)\n","  return gram\n","\n","\n","# 提取 mfcc 参数\n","def wav2mfcc(path):\n","  \n","  y, sr = librosa.load(path, sr=None, mono=1)\n","  audio_mac = librosa.feature.mfcc(y=y, sr=8000, n_mfcc=13)\n","\n","\n","  \n","\n","  mfcc_delta = librosa.feature.delta(audio_mac)\n","\n","\n","   \n","  mfcc_ddelta = librosa.feature.delta(mfcc_delta)\n","\n","\n","  \n","  c =np.hstack((audio_mac,mfcc_delta,mfcc_ddelta)) \n","  \n","  d = np.var(audio_mac,axis=1)\n","\n","\n","  e = np.mean(audio_mac, axis=1) # axis=0，计算每一列的均值\n","  f = np.var(mfcc_delta,axis=1)\n","\n","\n","  g = np.mean(mfcc_delta, axis=1) # axis=0，计算每一列的均值\n","  h = np.var(mfcc_ddelta,axis=1)\n","\n","\n","  i = np.mean(mfcc_ddelta, axis=1) # axis=0，计算每一列的均值\n","\n","  c =np.hstack((d,e,f,g,h,i)).T\n","  print(c.shape)\n","  #if e.shape[0] != 39:\n","    #print(\"eror:!!!!\",path)\n","  return c\n","\n","\n","# 存储处理过的数据，方便下一次的使用\n","def save_data_to_array(label_path):\n","  mfcc_vectors = []\n","  target = []\n","  i = 1\n","  labels = load_label(label_path=label_path)\n","  for j, label in enumerate(labels):\n","      path = label_path  + label\n","      print(path)\n","      wavfiles = [path + '/' + file for file in os.listdir(path)]\n","\n","      for wavfile in wavfiles:\n","\n","\n","        wav = wav2melgraf(wavfile)\n","        mfcc_vectors.append(wav)\n","        print(j)\n","        if j ==0:\n","          target.append(1)\n","        if j ==1:\n","          target.append(0)\n","        \n","  np.save(DATA, mfcc_vectors)\n","  np.save(TARGET, target)\n","  return mfcc_vectors, target\n","\n","\n","# 获取训练集与测试集\n","def get_train_test(split_ratio=.9, random_state=42):\n","  X = np.load(DATA,allow_pickle = True)\n","  y = np.load(TARGET,allow_pickle = True)\n","\n","  print(y.shape)\n","\n","  assert X.shape[0] == y.shape[0]\n","  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=(1 - split_ratio), random_state=random_state,\n","                                                      shuffle=True)\n","  return X_train, X_test, y_train, y_test\n","\n","\n","def main():\n"," \n","  x_train, x_test, y_train, y_test = get_train_test()\n","  print(x_train.shape)\n","  print(y_train.shape)\n","  #svclassifier = SVC(kernel='linear',C = 0.5)\n","  svclassifier = SVC(kernel='poly',C = 1.0)\n","  #svclassifier =SVC(kernel='rbf',C = 1.0)\n","  #svclassifier =SVC(kernel='sigmoid')\n","  svclassifier.fit(x_train, y_train)\n","\n","  \n","  print(svclassifier.score(x_train, y_train))   # 精度\n","  \n","  y_pred = svclassifier.predict(x_test)\n","  print(classification_report(y_test,y_pred))\n","\n","\n","\n","\n","\n","\n","\n","\n","if __name__ == \"__main__\":\n","  save_data_to_array(\"./SVM/\") \n","  main()\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1h2s0mEbouhg","colab_type":"code","colab":{}},"source":["### 提取mfcc\n","\n","\n","\n","\"\"\"\n","    此模块是SVM  训练  最终代码\n","    \n","\"\"\"\n","\n","from scipy import signal\n","\n","\n","from sklearn.metrics import classification_report\n","\n","from sklearn.externals import joblib\n","\n","\n","import os\n","import librosa\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.svm import SVC\n","\n","\n","\n","\n","DATA = 'datamfcc.npy'\n","TARGET = 'targetmfcc.npy'\n","\n","\n","# 加载标签\n","def load_label(label_path):\n","  label = os.listdir(label_path)\n","  return label\n","\n","def wav2melgraf(path):\n","  m_bands = 128\n","  s_rate = 8000\n","  win_length = int(0.1 * s_rate)  # Window length 15ms, 25ms, 50ms, 100ms, 200ms\n","  hop_length = int(0.01 * s_rate)  # Window shift  10ms\n","  n_fft = win_length\n","  y, sr = librosa.load(path, sr=8000)\n","  #进行傅里叶变换\n","  D = np.abs(librosa.stft(y, n_fft=n_fft, win_length=win_length, hop_length=hop_length,\n","                                window=signal.hamming, center=False)) ** 2\n","    #提取特征\n","  S = librosa.feature.melspectrogram(S=D, n_mels=m_bands)\n","  gram = librosa.power_to_db(S, ref=np.max)\n","  gram = np.transpose(gram, (1, 0))\n","  print(gram.shape)\n","  gram = gram[:300,:128]\n","\n","  if gram.shape[0] != 300 or gram.shape[1] != 128 :\n","    print(\"eror:!!!!\",path)\n","  return gram\n","\n","\n","# 提取 mfcc 参数\n","def wav2mfcc(path):\n","  \n","  y, sr = librosa.load(path, sr=None, mono=1)\n","  audio_mac = librosa.feature.mfcc(y=y, sr=8000, n_mfcc=13)\n","\n","\n","  \n","\n","  mfcc_delta = librosa.feature.delta(audio_mac)\n","\n","\n","   \n","  mfcc_ddelta = librosa.feature.delta(mfcc_delta)\n","\n","\n","  \n","  c =np.hstack((audio_mac,mfcc_delta,mfcc_ddelta)) \n","  \n","  d = np.var(audio_mac,axis=1)\n","\n","\n","  e = np.mean(audio_mac, axis=1) # axis=0，计算每一列的均值\n","  f = np.var(mfcc_delta,axis=1)\n","\n","\n","  g = np.mean(mfcc_delta, axis=1) # axis=0，计算每一列的均值\n","  h = np.var(mfcc_ddelta,axis=1)\n","\n","\n","  i = np.mean(mfcc_ddelta, axis=1) # axis=0，计算每一列的均值\n","\n","  c =np.hstack((d,e,f,g,h,i)).T\n","  print(c.shape)\n","  #if e.shape[0] != 39:\n","    #print(\"eror:!!!!\",path)\n","  return c\n","\n","\n","# 存储处理过的数据，方便下一次的使用\n","def save_data_to_array(label_path):\n","  mfcc_vectors = []\n","  target = []\n","  i = 1\n","  labels = load_label(label_path=label_path)\n","  for j, label in enumerate(labels):\n","      path = label_path  + label\n","      print(path)\n","      wavfiles = [path + '/' + file for file in os.listdir(path)]\n","\n","      for wavfile in wavfiles:\n","\n","\n","        wav =  wav2mfcc(wavfile)\n","        mfcc_vectors.append(wav)\n","        print(j)\n","        if j ==0:\n","          target.append(1)\n","        if j ==1:\n","          target.append(0)\n","        \n","  np.save(DATA, mfcc_vectors)\n","  np.save(TARGET, target)\n","  return mfcc_vectors, target\n","\n","\n","# 获取训练集与测试集\n","def get_train_test(split_ratio=.9, random_state=42):\n","  X = np.load(DATA,allow_pickle = True)\n","  y = np.load(TARGET,allow_pickle = True)\n","\n","  print(y.shape)\n","\n","  assert X.shape[0] == y.shape[0]\n","  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=(1 - split_ratio), random_state=random_state,\n","                                                      shuffle=True)\n","  return X_train, X_test, y_train, y_test\n","\n","\n","def main():\n"," \n","  x_train, x_test, y_train, y_test = get_train_test()\n","  print(x_train.shape)\n","  print(y_train.shape)\n","  svclassifier = SVC(kernel='linear',C = 0.6)\n","  #svclassifier = SVC(kernel='poly',C = 1.0)\n","  #svclassifier =SVC(kernel='rbf',C = 1.0)\n","  #svclassifier =SVC(kernel='sigmoid',C = 0.3)\n","  svclassifier.fit(x_train, y_train)\n","  \n","  joblib.dump(svclassifier, filename=\"./SVM1\")\n","  \n","  print(svclassifier.score(x_train, y_train))   # 精度\n","  \n","  y_pred = svclassifier.predict(x_test)\n","  print(classification_report(y_test,y_pred))\n","\n","\n","\n","\n","\n","\n","\n","\n","if __name__ == \"__main__\":\n","  #save_data_to_array(\"./SVM/\") \n","  main()\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GAqAkML4otCi","colab_type":"code","colab":{}},"source":["#keras最好的方法 实现f1分数  cnn2\n","\n","from __future__ import print_function\n","import keras\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n","from keras import backend as K\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from keras.callbacks import Callback\n","from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n","\n","global avgf1 \n","def f1(y_true, y_pred):\n","    def recall(y_true, y_pred):\n","        \"\"\"Recall metric.\n","\n","        Only computes a batch-wise average of recall.\n","\n","        Computes the recall, a metric for multi-label classification of\n","        how many relevant items are selected.\n","        \"\"\"\n","        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n","        recall = true_positives / (possible_positives + K.epsilon())\n","        return recall\n","\n","    def precision(y_true, y_pred):\n","        \"\"\"Precision metric.\n","\n","        Only computes a batch-wise average of precision.\n","\n","        Computes the precision, a metric for multi-label classification of\n","        how many selected items are relevant.\n","        \"\"\"\n","        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n","        precision = true_positives / (predicted_positives + K.epsilon())\n","        return precision\n","    precision = precision(y_true, y_pred)\n","    recall = recall(y_true, y_pred)\n","    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n","\n","\n","\n","\n","batch_size = 128\n","num_classes = 2\n","epochs = 100\n","img_rows, img_cols = 300, 128\n","\n","DATA = 'datagram3s.npy'\n","TARGET = 'targetgram3s.npy'\n","\n","X = np.load(DATA,allow_pickle = True)\n","y = np.load(TARGET,allow_pickle = True)\n","print(X.shape)\n","print(y.shape)\n","X = X.reshape(X.shape[0], img_rows, img_cols, 1)\n","\n","x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10,\n","                                                    shuffle=True)\n","x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n","x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n","input_shape = (img_rows, img_cols, 1)\n","\n","\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train /= 255\n","x_test /= 255\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n","\n","# convert class vectors to binary class matrices\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)\n","\n","\n","# build the neural net 建模型(卷积—relu-卷积-relu-池化-relu-卷积-relu-池化-全连接)\n","model = Sequential()\n","model.add(Conv2D(32, kernel_size=(3, 3),\n","                 activation='relu',\n","                 input_shape=input_shape)) # 32个过滤器，过滤器大小是3×3，32×26×26\n","model.add(MaxPooling2D(pool_size=(4, 4)))# 向下取样\n","model.add(Conv2D(4, (3, 3), activation='relu')) #64×24×24\n","model.add(MaxPooling2D(pool_size=(2, 2)))# 向下取样\n","model.add(Flatten()) #降维：将64×12×12降为1维（即把他们相乘起来）\n","model.add(Dense(500, activation='relu'))\n","model.add(Dropout(0.1))\n","model.add(Dense(50, activation='relu'))\n","model.add(Dense(num_classes, activation='softmax')) #全连接2层\n","\n","model.summary()\n","# compile the model 编译模型\n","model.compile(loss=keras.losses.categorical_crossentropy,\n","              optimizer=keras.optimizers.Adadelta(),\n","              metrics=[f1])\n","\n","# train the model 训练模型\n","history =model.fit(x_train, y_train,\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          verbose=1,\n","          validation_data=(x_test, y_test),)\n","# test the model 测试模型\n","\n","\n","score = model.evaluate(x_test, y_test, verbose=0)\n","model.save('cnn2.h5')\n","array1=np.array(history.history['val_f1'])\n","np.save(\"./temp/cnn2.npy\", array1)\n","print('Test accuracy:',score[1])\n","plt.plot(range(100),array1,'r', label='CNN2')\n","plt.title(\"model F1_score\")\n","plt.ylabel(\"F1_score\")\n","plt.xlabel(\"epoch\")\n","\n","\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wkEVvbzhNzPH","colab_type":"code","colab":{}},"source":["# 实现f1分数  cnn4\n","\n","from __future__ import print_function\n","import keras\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n","from keras import backend as K\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from keras.callbacks import Callback\n","from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n","\n","global avgf1 \n","def f1(y_true, y_pred):\n","    def recall(y_true, y_pred):\n","        \"\"\"Recall metric.\n","\n","        Only computes a batch-wise average of recall.\n","\n","        Computes the recall, a metric for multi-label classification of\n","        how many relevant items are selected.\n","        \"\"\"\n","        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n","        recall = true_positives / (possible_positives + K.epsilon())\n","        return recall\n","\n","    def precision(y_true, y_pred):\n","        \"\"\"Precision metric.\n","\n","        Only computes a batch-wise average of precision.\n","\n","        Computes the precision, a metric for multi-label classification of\n","        how many selected items are relevant.\n","        \"\"\"\n","        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n","        precision = true_positives / (predicted_positives + K.epsilon())\n","        return precision\n","    precision = precision(y_true, y_pred)\n","    recall = recall(y_true, y_pred)\n","    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n","\n","\n","\n","\n","batch_size = 128\n","num_classes = 2\n","epochs = 100\n","img_rows, img_cols = 300, 128\n","\n","DATA = 'datagram3s.npy'\n","TARGET = 'targetgram3s.npy'\n","\n","X = np.load(DATA,allow_pickle = True)\n","y = np.load(TARGET,allow_pickle = True)\n","print(X.shape)\n","print(y.shape)\n","X = X.reshape(X.shape[0], img_rows, img_cols, 1)\n","\n","x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10,\n","                                                    shuffle=True)\n","x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n","x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n","input_shape = (img_rows, img_cols, 1)\n","\n","\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train /= 255\n","x_test /= 255\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n","\n","# convert class vectors to binary class matrices\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)\n","\n","\n","# build the neural net 建模型(卷积—relu-卷积-relu-池化-relu-卷积-relu-池化-全连接)\n","model = Sequential()\n","model.add(Conv2D(8, kernel_size=(3, 3),\n","                 activation='relu',\n","                 input_shape=input_shape)) # 32个过滤器，过滤器大小是3×3，32×26×26\n","model.add(MaxPooling2D(pool_size=(2, 2)))# 向下取样\n","model.add(Conv2D(16, (3, 3), activation='relu')) #64×24×24\n","model.add(MaxPooling2D(pool_size=(2, 2)))# 向下取样\n","model.add(Conv2D(16, kernel_size=(3, 3),\n","                 activation='relu',\n","                 input_shape=input_shape)) # 32个过滤器，过滤器大小是3×3，32×26×26\n","model.add(MaxPooling2D(pool_size=(2, 2)))# 向下取样\n","model.add(Conv2D(32, (3, 3), activation='relu')) #64×24×24\n","model.add(MaxPooling2D(pool_size=(2, 2)))# 向下取样\n","model.add(Flatten()) #降维：将64×12×12降为1维（即把他们相乘起来）\n","model.add(Dense(500, activation='relu'))\n","model.add(Dropout(0.1))\n","model.add(Dense(50, activation='relu'))\n","model.add(Dense(num_classes, activation='softmax')) #全连接2层\n","\n","model.summary()\n","# compile the model 编译模型\n","model.compile(loss=keras.losses.categorical_crossentropy,\n","              optimizer=keras.optimizers.Adadelta(),\n","              metrics=[f1])\n","\n","# train the model 训练模型\n","history = model.fit(x_train, y_train,\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          verbose=1,\n","          validation_data=(x_test, y_test),)\n","# test the model 测试模型\n","score = model.evaluate(x_test, y_test, verbose=0)\n","print('Test accuracy:',score[1])\n","model.save('cnn4.h5')\n","array1=np.array(history.history['val_f1'])\n","np.save(\"./temp/cnn4.npy\", array1)\n","\n","plt.plot(range(100),array1,'g', label='CNN4')\n","plt.legend() # 展示图例\n","plt.title(\"model F1_score\")\n","plt.ylabel(\"F1_score\")\n","plt.xlabel(\"epoch\")\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vEUiMx1CO5-I","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pFWaVJeYocDy","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mJaO9fuNlSpr","colab_type":"code","colab":{}},"source":["# 实现f1分数  cnn6\n","\n","from __future__ import print_function\n","import keras\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n","from keras import backend as K\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from keras.callbacks import Callback\n","\n","\n","global avgf1 \n","def f1(y_true, y_pred):\n","    def recall(y_true, y_pred):\n","        \"\"\"Recall metric.\n","\n","        Only computes a batch-wise average of recall.\n","\n","        Computes the recall, a metric for multi-label classification of\n","        how many relevant items are selected.\n","        \"\"\"\n","        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n","        recall = true_positives / (possible_positives + K.epsilon())\n","        return recall\n","\n","    def precision(y_true, y_pred):\n","        \"\"\"Precision metric.\n","\n","        Only computes a batch-wise average of precision.\n","\n","        Computes the precision, a metric for multi-label classification of\n","        how many selected items are relevant.\n","        \"\"\"\n","        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n","        precision = true_positives / (predicted_positives + K.epsilon())\n","        return precision\n","    precision = precision(y_true, y_pred)\n","    recall = recall(y_true, y_pred)\n","    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n","\n","\n","\n","\n","batch_size = 128\n","num_classes = 2\n","epochs = 100\n","img_rows, img_cols = 300, 128\n","\n","DATA = 'datagram3s.npy'\n","TARGET = 'targetgram3s.npy'\n","\n","X = np.load(DATA,allow_pickle = True)\n","y = np.load(TARGET,allow_pickle = True)\n","print(X.shape)\n","print(y.shape)\n","X = X.reshape(X.shape[0], img_rows, img_cols, 1)\n","\n","x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10,\n","                                                    shuffle=True)\n","x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n","x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n","input_shape = (img_rows, img_cols, 1)\n","\n","\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train /= 255\n","x_test /= 255\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n","\n","# convert class vectors to binary class matrices\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)\n","\n","\n","# build the neural net 建模型(卷积—relu-卷积-relu-池化-relu-卷积-relu-池化-全连接)\n","model = Sequential()\n","model.add(Conv2D(32, kernel_size=(3, 3),\n","                 activation='relu',\n","                 input_shape=input_shape)) # 32个过滤器，过滤器大小是3×3，32×26×26\n","model.add(MaxPooling2D(pool_size=(2, 2)))# 向下取样\n","model.add(Conv2D(32, (3, 3), activation='relu')) #64×24×24\n","model.add(MaxPooling2D(pool_size=(2, 2)))# 向下取样\n","model.add(Conv2D(16, kernel_size=(3, 3),\n","                 activation='relu',\n","                 input_shape=input_shape)) # 32个过滤器，过滤器大小是3×3，32×26×26\n","model.add(MaxPooling2D(pool_size=(2, 2)))# 向下取样\n","model.add(Conv2D(16, (3, 3), activation='relu')) #64×24×24\n","model.add(MaxPooling2D(pool_size=(2, 2)))# 向下取样\n","model.add(Conv2D(16, kernel_size=(3, 3),\n","                 activation='relu',\n","                 input_shape=input_shape)) # 32个过滤器，过滤器大小是3×3，32×26×26\n","model.add(MaxPooling2D(pool_size=(2, 2)))# 向下取样\n","\n","model.add(Flatten()) #降维：将64×12×12降为1维（即把他们相乘起来）\n","model.add(Dense(500, activation='relu'))\n","#model.add(Dropout(0.1))\n","model.add(Dense(50, activation='relu'))\n","model.add(Dense(num_classes, activation='softmax')) #全连接2层\n","\n","model.summary()\n","# compile the model 编译模型\n","model.compile(loss=keras.losses.categorical_crossentropy,\n","              optimizer=keras.optimizers.Adadelta(),\n","              metrics=[f1])\n","\n","# train the model 训练模型\n","history = model.fit(x_train, y_train,\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          verbose=1,\n","          validation_data=(x_test, y_test),)\n","# test the model 测试模型\n","score = model.evaluate(x_test, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])\n","model.save('cnn6.h5')\n","array1=np.array(history.history['val_f1'])\n","print(\"max is：\",np.max(array1))   \n","np.save(\"./temp/cnn6.npy\", array1)\n","\n","plt.plot(range(100),array1,'y', label='CNN6')\n","plt.legend() # 展示图例\n","plt.title(\"model F1_score\")\n","plt.ylabel(\"F1_score\")\n","plt.xlabel(\"epoch\")\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2IRoF0I75Kmj","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NAdfaRH8oej8","colab_type":"code","colab":{}},"source":["# LSTM\n","\n","from __future__ import print_function\n","import keras\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import *\n","from keras import backend as K\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from keras.callbacks import Callback\n","\n","\n","global avgf1 \n","def f1(y_true, y_pred):\n","    def recall(y_true, y_pred):\n","        \"\"\"Recall metric.\n","\n","        Only computes a batch-wise average of recall.\n","\n","        Computes the recall, a metric for multi-label classification of\n","        how many relevant items are selected.\n","        \"\"\"\n","        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n","        recall = true_positives / (possible_positives + K.epsilon())\n","        return recall\n","\n","    def precision(y_true, y_pred):\n","        \"\"\"Precision metric.\n","\n","        Only computes a batch-wise average of precision.\n","\n","        Computes the precision, a metric for multi-label classification of\n","        how many selected items are relevant.\n","        \"\"\"\n","        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n","        precision = true_positives / (predicted_positives + K.epsilon())\n","        return precision\n","    precision = precision(y_true, y_pred)\n","    recall = recall(y_true, y_pred)\n","    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n","\n","\n","\n","TIME_STEPS = 300\n","INPUT_SIZE = 128\n","CELL_SIZE = 50\n","batch_size = 50\n","num_classes = 2\n","epochs = 100\n","img_rows, img_cols = 300, 128\n","\n","DATA = 'datagram3s.npy'\n","TARGET = 'targetgram3s.npy'\n","\n","X = np.load(DATA,allow_pickle = True)\n","y = np.load(TARGET,allow_pickle = True)\n","print(X.shape)\n","print(y.shape)\n","X = X.reshape(X.shape[0], img_rows, img_cols, 1)\n","\n","x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10,\n","                                                    shuffle=True)\n","x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols)\n","x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols)\n","\n","\n","\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train /= 255\n","x_test /= 255\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n","\n","# convert class vectors to binary class matrices\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)\n","\n","\n","# build the neural net \n","model = Sequential()\n","model.add(LSTM(units=CELL_SIZE, input_shape=(TIME_STEPS, INPUT_SIZE),return_sequences=True))\n","model.add(LSTM(units=100, return_sequences=False))\n","model.add(Dense(num_classes, activation='softmax'))\n","\n","model.summary()\n","# compile the model 编译模型\n","model.compile(loss=keras.losses.categorical_crossentropy,\n","              optimizer=keras.optimizers.Adadelta(),\n","              metrics=[f1])\n","\n","# train the model 训练模型\n","history = model.fit(x_train, y_train,\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          verbose=1,\n","          validation_data=(x_test, y_test),)\n","# test the model 测试模型\n","score = model.evaluate(x_test, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])\n","model.save('LSTM.h5')\n","array1=np.array(history.history['val_f1'])\n","np.save(\"./temp/LSTM.npy\", array1)\n","print(\"max is：\",np.max(array1)) \n","plt.plot(range(100),array1,'y', label='LSTM')\n","plt.legend() # 展示图例\n","plt.title(\"model F1_score\")\n","plt.ylabel(\"F1_score\")\n","plt.xlabel(\"epoch\")\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cvf8drbDAylc","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qlAE25OQsE_6","colab_type":"code","colab":{}},"source":["\n","##3DCNN\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.models import Sequential, load_model\n","from keras.layers import *\n","from keras.layers.convolutional import Convolution3D, MaxPooling3D\n","\n","from keras.optimizers import SGD, RMSprop\n","from keras.utils import np_utils, generic_utils\n","\n","import tensorflow as tf\n","import os\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import cv2\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import cross_val_score\n","from sklearn import preprocessing\n","from keras import backend as K\n","from keras.regularizers import l2\n","OUTPUT_FILE1 = \"./3DCNN/baby/\"\n","OUTPUT_FILE2 = \"./3DCNN/other/\"\n","\n","# image specification\n","img_rows, img_cols,img_depth =64,64,18#resize parameters\n","\n","\n","# Training data\n","\n","X_tr=[]           # variable to store entire dataset\n","\n","#Reading boxing action class\n","def f1(y_true, y_pred):\n","    def recall(y_true, y_pred):\n","        \"\"\"Recall metric.\n","\n","        Only computes a batch-wise average of recall.\n","\n","        Computes the recall, a metric for multi-label classification of\n","        how many relevant items are selected.\n","        \"\"\"\n","        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n","        recall = true_positives / (possible_positives + K.epsilon())\n","        return recall\n","\n","    def precision(y_true, y_pred):\n","        \"\"\"Precision metric.\n","\n","        Only computes a batch-wise average of precision.\n","\n","        Computes the precision, a metric for multi-label classification of\n","        how many selected items are relevant.\n","        \"\"\"\n","        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n","        precision = true_positives / (predicted_positives + K.epsilon())\n","        return precision\n","    precision = precision(y_true, y_pred)\n","    recall = recall(y_true, y_pred)\n","    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n","\n","def read_data():\n","    '''\n","    read training data from KTH dataset\n","    '''\n","    X_tr=[] \n","    #Reading boxing action class\n","    listing = os.listdir(OUTPUT_FILE1)\n","    for vid in listing:\n","        vid = OUTPUT_FILE1+vid\n","        frames = []\n","        \n","        #print(vid)\n","        cap = cv2.VideoCapture(vid)\n","        fps = cap.get(5)\n","\n","        number = int(fps*3)\n","        D = (number)/img_depth\n","        i = 0\n","        d = int(D)\n","        #print(d)\n","        for k in range(number):\n","          \n","          ret, frame = cap.read()\n","          if ret ==0:\n","            cap = cv2.VideoCapture(vid)\n","            \n","            frames = []\n","            D = (k)/img_depth\n","            i = 0\n","            d = int(D)\n","            print(d)\n","            for j in range(k):\n","              ret, frame = cap.read()\n","              if(j%d ==0):\n","                frame=cv2.resize(mg,(img_rows,img_cols),interpolation=cv2.INTER_AREA)\n","                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","                frames.append(gray)\n","                i = i+1\n","                if(i>=17):\n","                  break\n","                \n","          \n","          if(k%d ==0):\n","            frame=cv2.resize(frame,(img_rows,img_cols),interpolation=cv2.INTER_AREA)\n","            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","            frames.append(gray)\n","            if(i>=17):\n","              break\n","            i = i+1\n","        \n","        cap.release()\n","        cv2.destroyAllWindows()\n","        inputs=np.array(frames)\n","        ipt=np.rollaxis(np.rollaxis(inputs,2,0),2,0)\n","        #print(ipt.shape)\n","        if ipt.shape[2]!=18:\n","          print(\"error!!!\",vid)\n","          print(ipt.shape)\n","\n","        X_tr.append(ipt)\n","    print(\"baby done\",len(X_tr))\n","\n","\n","    #Reading hand clapping action class\n","    listing2 = os.listdir(OUTPUT_FILE2)\n","    for vid2 in listing2:\n","        vid2 = OUTPUT_FILE2+vid2\n","        #print(vid2)\n","        frames = []\n","        cap = cv2.VideoCapture(vid2)\n","        fps = cap.get(5)\n","        number = int(fps*3)\n","        D = (number)/img_depth\n","        i = 0\n","        d = int(D)\n","        \n","        for k in range(number):\n","          ret, frame = cap.read()\n","          if(k%d ==0):\n","            \n","            frame=cv2.resize(frame,(img_rows,img_cols),interpolation=cv2.INTER_AREA)\n","            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","            frames.append(gray)\n","            if(i>=17):\n","              break\n","            i = i+1\n","\n","        cap.release()\n","        cv2.destroyAllWindows()\n","        input=np.array(frames)\n","        \n","        ipt=np.rollaxis(np.rollaxis(input,2,0),2,0)\n","\n","        X_tr.append(ipt)\n","    print(\"others done\",len(X_tr))\n","    \n","\n","    return X_tr\n","\n","##X_tr=read_data()\n","#X_tr_array = np.array(X_tr)   # convert the frames read into array\n","\n","\n","#np.save(\"./picture64.npy\",X_tr_array)\n","X_tr_array = np.load(\"./picture64.npy\",allow_pickle = True)\n","num_samples = len(X_tr_array)\n","print(num_samples)\n","\n","# Assign Label to each class\n","label=np.ones((num_samples,), dtype = int)   #创建相同规格的lable\n","#each class has 100 videos\n","label[0:1399] = 1\n","label[1399:] = 0\n","\n","y_train = label\n","\n","#600 num_samples\n","\n","print('X_Train shape:', X_tr_array.shape)#(600, 32, 32, 30)\n","train_set = np.zeros((num_samples, img_rows, img_cols, img_depth, 1))\n","\n","for h in range(num_samples):\n","    train_set[h,:,:,:,0]=X_tr_array[h,:,:,:]   #这里增加一维度，用来符合3D卷积网络的输入\n","\n","patch_size = 10    # img_depth or number of frames used for each video\n","print(train_set.shape, 'train samples')\n","\n","# CNN Training parameters\n","\n","batch_size = 20    #\n","nb_classes = 2    #\n","nb_epoch = 100   #训练轮数\n","\n","# convert class vectors to binary class matrices\n","Y_train = np_utils.to_categorical(y_train, nb_classes)#将标签转化为int编码\n","\n","\n","# number of convolutional filters to use at each layer 每一层卷积器数量\n","nb_filters = [  32,   # 1st conv layer\n","                64    # 2nd\n","             ]\n","\n","# level of pooling to perform at each layer (POOL x POOL)\n","nb_pool = [3, 3]\n","\n","# level of convolution to perform at each layer (CONV x CONV)\n","nb_conv = [5,5]\n","\n","# Pre-processing\n","train_set = train_set.astype('float32')\n","train_set -= np.mean(train_set)\n","train_set /= np.max(train_set)\n","\n","\n","weight_decay = 0.005\n","\n","\n","\n","# Define model\n","model_exists = os.path.exists('current.h5')\n","if (model_exists):\n","    model = load_model('current.h5')\n","    print(\"**************************************************\")\n","    print(\"current.h5 model loaded\")\n","\n","else:\n","    model = Sequential()\n","    print('input shape', img_rows, 'rows', img_cols, 'cols', patch_size, 'patchsize')\n","    model.add(Convolution3D(nb_filters[0],(3,3,3),input_shape=(img_rows, img_cols,img_depth ,1),activation='relu',kernel_regularizer=l2(weight_decay)))\n","    model.add(MaxPool3D((2,2,1),strides=(2,2,1),padding='same'))\n","    model.add(Convolution3D(nb_filters[1],(2,2,2),activation='relu',kernel_regularizer=l2(weight_decay)))\n","    model.add(MaxPool3D((2,2,2),strides=(2,2,2),padding='same'))\n","    model.add(Convolution3D(nb_filters[1],(2,2,2),activation='relu',kernel_regularizer=l2(weight_decay)))\n","    model.add(MaxPool3D((2,2,2),strides=(2,2,2),padding='same'))\n","    model.add(Flatten())#把数据变为一维\n","    model.add(Dense(1000))\n","    model.add(Dropout(0.1))#在训练过程中每次更新参数时随机断开一定百分比的输入神经元连接，用于防止过拟合。\n","\n","    #model.add(Dropout(0.3))#在训练过程中每次更新参数时随机断开一定百分比的输入神经元连接，用于防止过拟合。\n","    model.add(Dense(50))\n","    model.add(Dense(nb_classes))\n","    model.add(Activation('softmax'))\n","    model.compile(loss='categorical_crossentropy', optimizer='RMSprop',     metrics=[f1])\n","          #损失函数             优化器   加速梯度下降法  评价函数\n","    model.summary()#print the model\n","\n","# Split the data\n","X_train_new, X_val_new, y_train_new,y_val_new = train_test_split(train_set, Y_train, test_size=0.2, random_state=10)\n","print('split end')\n","# Train the model\n","history = model.fit(X_train_new,\n","\t\t\t    y_train_new,\n","\t\t\t    validation_data=(X_val_new,y_val_new),\n","\t\t\t    batch_size=batch_size,\n","\t\t\t    epochs = nb_epoch,\n","\t\t\t    shuffle=True#打乱输入数据\n","          )#tensorboard --logdir=./log\n","print('train end')\n","\n","score = model.evaluate(X_val_new,y_val_new,batch_size=batch_size)\n","# Print the results\n","\n","print('**********************************************')\n","print('Test score:', score)#最终结果\n","model.save('3DCNN.h5')\n","array1=np.array(history.history['val_f1'])\n","np.save(\"./temp/3DCNN.npy\", array1)\n","print(\"max is：\",np.max(array1)) \n","plt.plot(range(100),array1,'y', label='3DCNN')\n","plt.legend() # 展示图例\n","plt.title(\"model F1_score\")\n","plt.ylabel(\"F1_score\")\n","plt.xlabel(\"epoch\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RfBz7EhIb0UK","colab_type":"code","colab":{}},"source":["#多模态网络CNN+CNN+DNN\n","from keras.utils import np_utils, generic_utils\n","from sklearn.model_selection import train_test_split\n","from keras.layers import *\n","from keras import Input, Model\n","from keras.utils import plot_model\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from keras import backend as K\n","gram_rows, gram_cols,gram_depth =100,128,1#resize parameters\n","\n","img_rows, img_cols,img_depth =64,64,18#resize parameters\n","# number of convolutional filters to use at each layer 每一层卷积器数量\n","nb_filters = [  32,   # 1st conv layer\n","                32    # 2nd\n","             ]\n","\n","nb_pool = [3, 3]\n","nb_classes = 2\n","\n","\n","nb_conv = [5,5]\n","\n","\n","def f1(y_true, y_pred):\n","    def recall(y_true, y_pred):\n","        \"\"\"Recall metric.\n","\n","        Only computes a batch-wise average of recall.\n","\n","        Computes the recall, a metric for multi-label classification of\n","        how many relevant items are selected.\n","        \"\"\"\n","        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n","        recall = true_positives / (possible_positives + K.epsilon())\n","        return recall\n","\n","    def precision(y_true, y_pred):\n","        \"\"\"Precision metric.\n","\n","        Only computes a batch-wise average of precision.\n","\n","        Computes the precision, a metric for multi-label classification of\n","        how many selected items are relevant.\n","        \"\"\"\n","        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n","        precision = true_positives / (predicted_positives + K.epsilon())\n","        return precision\n","    precision = precision(y_true, y_pred)\n","    recall = recall(y_true, y_pred)\n","    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n","\n","\n","\n","\n","\n","def multi_input_model():\n","    \"\"\"构建多输入模型\"\"\"\n","\n","\n","    input1 = Input(shape = (gram_rows,gram_cols,gram_depth),name='input1')\n","    x = Conv2D(32, kernel_size=(5,5), activation='relu', input_shape=(gram_rows, gram_cols, gram_depth))(input1)\n","    x = MaxPool2D(pool_size=(3,3), strides=(2,2))(x)\n","    x = Conv2D(8, kernel_size=(5,5), activation='relu')(x)\n","    x = MaxPool2D(pool_size=(3,3), strides=(2,2))(x)\n","    x  = (Flatten())(x)\n","    output1 = Dense(256)(x)\n"," \n","    input2 = Input(shape = (gram_rows,gram_cols,gram_depth),name='input2')\n","    x = Conv2D(32, kernel_size=(5,5), activation='relu', input_shape=(gram_rows, gram_cols, gram_depth))(input2)\n","    x = MaxPool2D(pool_size=(3,3), strides=(2,2))(x)\n","    x = Conv2D(8, kernel_size=(5,5), activation='relu')(x)\n","    x = MaxPool2D(pool_size=(3,3), strides=(2,2))(x)\n","    x  = (Flatten())(x)\n","    output2 = Dense(256)(x)\n","    \n","    input3 = Input(shape = (gram_rows,gram_cols,gram_depth),name='input3')\n","    x = Conv2D(32, kernel_size=(5,5), activation='relu', input_shape=(gram_rows, gram_cols, gram_depth))(input3)\n","    x = MaxPool2D(pool_size=(3,3), strides=(2,2))(x)\n","    x = Conv2D(8, kernel_size=(5,5), activation='relu')(x)\n","    x = MaxPool2D(pool_size=(3,3), strides=(2,2))(x)\n","    x  = (Flatten())(x)\n","    output3 = Dense(256)(x)\n","  \n","\n","\n","\n","    input4 = Input(shape = (img_rows,img_cols*6,gram_depth),name='input4')\n","    x = Conv2D(32, kernel_size=(5,5), activation='relu', input_shape=(gram_rows, gram_cols, gram_depth))(input1)\n","    x = MaxPool2D(pool_size=(3,3), strides=(2,2))(x)\n","    x = Conv2D(8, kernel_size=(5,5), activation='relu')(x)\n","    x = MaxPool2D(pool_size=(3,3), strides=(2,2))(x)\n","    x  = (Flatten())(x)\n","    output4 = Dense(256)(x)\n","    \n","    \n","    input6 = Input(shape = (img_rows,img_cols*6,gram_depth),name='input5')\n","    x = Conv2D(32, kernel_size=(5,5), activation='relu', input_shape=(gram_rows, gram_cols, gram_depth))(input1)\n","    x = MaxPool2D(pool_size=(3,3), strides=(2,2))(x)\n","    x = Conv2D(8, kernel_size=(5,5), activation='relu')(x)\n","    x = MaxPool2D(pool_size=(3,3), strides=(2,2))(x)\n","    x  = (Flatten())(x)\n","    output5 = Dense(256)(x)\n","   \n","\n","    input5 = Input(shape = (img_rows,img_cols*6,gram_depth),name='input6')\n","    x = Conv2D(32, kernel_size=(5,5), activation='relu', input_shape=(gram_rows, gram_cols, gram_depth))(input1)\n","    x = MaxPool2D(pool_size=(3,3), strides=(2,2))(x)\n","    x = Conv2D(8, kernel_size=(5,5), activation='relu')(x)\n","    x = MaxPool2D(pool_size=(3,3), strides=(2,2))(x)\n","    x  = (Flatten())(x)\n","    output6 = Dense(256)(x)\n"," \n","\n","\n","\n","\n","    \n","    x1 = Concatenate(axis=1)([output1,output4])\n","    print(K.int_shape(x1))\n","    \n","\n","    x2 = Concatenate(axis=1)([output2,output5])\n","    print(K.int_shape(x2))\n","    x3 = Concatenate(axis=1)([output3,output6])\n","    \n","    x = Concatenate(axis=1)([x1,x2,x3])\n","    print(K.int_shape(x))\n","    x = Dense(100, activation='relu')(x)\n","    x = Dropout(0.1)(x)\n","    x = Dense(50, activation='relu')(x)\n","    x = Dense(2, activation='softmax')(x)\n","    \n","  \n","    model = Model(inputs=[input1, input2,input3, input4,input5, input6], outputs=[x])\n","    model.summary()\n","  \n","    return model\n","\n","if __name__ == '__main__':\n","    # 产生训练数据\n","\n","    X_tr_array = np.load(\"./picture64.npy\",allow_pickle = True)\n","    num_samples = len(X_tr_array)\n","\n","    # Assign Label to each class\n","    label=np.ones((num_samples,), dtype = int)   #创建相同规格的lable\n","    #each class has 100 videos\n","    label[0:1399] = 1\n","    label[1399:] = 0\n","    y_train = label\n","    \n","    train_set = np.zeros((num_samples, img_rows, img_cols, img_depth, 1))\n","    y_train = np_utils.to_categorical(y_train, nb_classes)#将标签转化为int编码\n","    for h in range(num_samples):\n","      train_set[h,:,:,:,0]=X_tr_array[h,:,:,:]   #这里增加一维度，用来符合3D卷积网络的输入#(600, 64, 64, 18,1)\n","    train_set = train_set.astype('float32')\n","    train_set -= np.mean(train_set)\n","    train_set /= np.max(train_set)\n","    #print('X_Train shape:', train_set.shape)#(600, 32, 32, 39,1)    \n","    X_train_new, X_val_new, y_train_new,y_val_new = train_test_split(train_set, y_train, test_size=0.2, random_state=4)   # 视频的分配结束\n","    X1 =  X_train_new[:,:,:,0:6,:]\n","    X1 = X1.reshape(2459,64,64*6,1)\n","    X2 =  X_train_new[:,:,:,6:12,:]\n","    X2 = X2.reshape(2459,64,64*6,1)\n","    X3 =  X_train_new[:,:,:,12:18,:]\n","    X3 = X3.reshape(2459,64,64*6,1)\n","    Y1 =  X_val_new[:,:,:,0:6,:]\n","    Y1 = Y1.reshape(615,64,64*6,1)\n","    Y2 =  X_val_new[:,:,:,6:12,:]\n","    Y2 = Y2.reshape(615,64,64*6,1)\n","    Y3 =  X_val_new[:,:,:,12:18,:]\n","    Y3 = Y3.reshape(615,64,64*6,1)\n","    print(X1.shape)\n","\n","\n","    X = np.load('datagram3s.npy',allow_pickle = True)\n","    y = np.load('targetgram3s.npy',allow_pickle = True)\n","    X = X.astype('float32')\n","    X -= np.mean(X)\n","    X /= np.max(X)\n","    X = X.reshape(X.shape[0], 300, 128, 1)\n","    #print('X_Train shape:', X.shape)#(600, 32, 32, 39,1) \n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)\n","                                                    \n","    X4 =  X_train[:,0:100,:,:]\n","    X5 =  X_train[:,100:200,:,:]\n","    X6 =  X_train[:,200:300,:,:]\n","    Y4 =  X_test[:,0:100,:,:]\n","    Y5 =  X_test[:,100:200,:,:]\n","    Y6 =  X_test[:,200:300,:,:]\n","    model = multi_input_model()\n","    # 保存模型图\n","    plot_model(model, 'Multi_input_model.png')\n"," \n","    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[f1])\n","    history = model.fit([X4,X5,X6,X1,X2,X3], y_train_new, epochs=100,validation_data=([Y4,Y5,Y6,Y1,Y2,Y3], y_val_new), batch_size=64,shuffle=True)\n","\n","    model.save('ccd.h5')\n","    array1=np.array(history.history['val_f1'])\n","    np.save(\"./temp/ccd.npy\", array1)\n","    print(\"max is：\",np.max(array1)) \n","    plt.plot(range(100),array1,'y', label='CNN+3DCNN+DNN')\n","    plt.legend() # 展示图例\n","    plt.title(\"model F1_score\")\n","    plt.ylabel(\"F1_score\")\n","    plt.xlabel(\"epoch\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WyNkeKEMW4te","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"k4zqW4n3zzm2","colab_type":"code","colab":{}},"source":["#多模态网络CNN+3DCNN+DNN\n","from keras.utils import np_utils, generic_utils\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from keras.layers import *\n","from keras import Input, Model\n","from keras.utils import plot_model\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from keras import backend as K\n","img_rows, img_cols,img_depth =64,64,18#resize parameters\n","# number of convolutional filters to use at each layer 每一层卷积器数量\n","nb_filters = [  32,   # 1st conv layer\n","                8    # 2nd\n","             ]\n","\n","# level of pooling to perform at each layer (POOL x POOL)\n","nb_pool = [3, 3]\n","nb_classes = 2\n","\n","# level of convolution to perform at each layer (CONV x CONV)\n","nb_conv = [5,5]\n","def f1(y_true, y_pred):\n","    def recall(y_true, y_pred):\n","        \"\"\"Recall metric.\n","\n","        Only computes a batch-wise average of recall.\n","\n","        Computes the recall, a metric for multi-label classification of\n","        how many relevant items are selected.\n","        \"\"\"\n","        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n","        recall = true_positives / (possible_positives + K.epsilon())\n","        return recall\n","\n","    def precision(y_true, y_pred):\n","        \"\"\"Precision metric.\n","\n","        Only computes a batch-wise average of precision.\n","\n","        Computes the precision, a metric for multi-label classification of\n","        how many selected items are relevant.\n","        \"\"\"\n","        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n","        precision = true_positives / (predicted_positives + K.epsilon())\n","        return precision\n","    precision = precision(y_true, y_pred)\n","    recall = recall(y_true, y_pred)\n","    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"," \n","def multi_input_model():\n","    \"\"\"构建多输入模型\"\"\"\n","\n","\n","    input1 = Input(shape = (300,128,1),name='input1')\n","    x = Conv2D(32, kernel_size=(5,5), activation='relu', input_shape=(300, 128, 1))(input1)\n","    x = MaxPool2D(pool_size=(3,3), strides=(3,3))(x)\n","    x = Conv2D(64, kernel_size=(5,5), activation='relu')(x)\n","    x = MaxPool2D(pool_size=(3,3), strides=(3,3))(x)\n","\n","    x = Flatten()(x)\n","    output1 = Dense(256, activation='relu')(x)\n","   \n","\n","    input2 = Input(shape = (64,64,18,1), name='input2')\n","    x = Convolution3D(nb_filters[0],(5,5,3),input_shape=(img_rows, img_cols,18,1),activation='relu')(input2)\n","    x = MaxPooling3D(pool_size=(3, 3, 3))(x)\n","    x = Convolution3D(nb_filters[1],(3,3,3),activation='relu')(x)\n","    x = MaxPooling3D(pool_size=(3, 3, 3))(x)\n","    x = (Flatten())(x)\n","    output2 = Dense(256)(x)\n","    \n","    \n","    x = Concatenate(axis = 1)([output1,output2])\n","    \n","    x = Dense(10, activation='relu')(x)\n","    x =  Dense(nb_classes,  activation='softmax')(x)\n","  \n","    model = Model(inputs=[input1, input2], outputs=[x])\n","    model.summary()\n","  \n","    return model\n"," \n","if __name__ == '__main__':\n","    # 产生训练数据\n","\n","    X_tr_array = np.load(\"./picture64.npy\",allow_pickle = True)\n","    num_samples = len(X_tr_array)\n","    print(num_samples)\n","\n","    # Assign Label to each class\n","    label=np.ones((num_samples,), dtype = int)   #创建相同规格的lable\n","    #each class has 100 videos\n","    label[0:1399] = 1\n","    label[1399:] = 0\n","    y_train = label\n","    print('X_Train shape:', X_tr_array.shape)#(600, 32, 32, 39,1)\n","    train_set = np.zeros((num_samples, img_rows, img_cols, img_depth, 1))\n","    y_train = np_utils.to_categorical(y_train, nb_classes)#将标签转化为int编码\n","    for h in range(num_samples):\n","      train_set[h,:,:,:,0]=X_tr_array[h,:,:,:]   #这里增加一维度，用来符合3D卷积网络的输入#(600, 32, 32, 39,1)\n","    train_set = train_set.astype('float32')\n","    train_set -= np.mean(train_set)\n","    train_set /= np.max(train_set)\n","    print('X_Train shape:', train_set.shape)#(600, 32, 32, 39,1)    \n","    X_train_new, X_val_new, y_train_new,y_val_new = train_test_split(train_set, y_train, test_size=0.2, random_state=4)   # 视频的分配结束\n","    X = np.load('datagram3s.npy',allow_pickle = True)\n","    y = np.load('targetgram3s.npy',allow_pickle = True)\n","    X = X.astype('float32')\n","    X -= np.mean(X)\n","    X /= np.max(X)\n"," \n","    X = X.reshape(X.shape[0], 300, 128, 1)\n","    print('X_Train shape:', X.shape)#(600, 32, 32, 39,1) \n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)\n","                                                    \n","    #patch_size = 39    # img_depth or number of frames used for each video\n","    model = multi_input_model()\n","    # 保存模型图\n","    plot_model(model, 'Multi_input_model.png')\n"," \n","    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[f1])\n","    history = model.fit([X_train, X_train_new], y_train_new, epochs=100,validation_data=([X_test, X_val_new], y_val_new), batch_size=20,shuffle=True)\n","    #score = model.evaluate([X_test,X_val_new],y_val_new,batch_size=20)\n","    #print('History', hist.history)\n","    model.save('c3cd.h5')\n","    array1=np.array(history.history['val_f1'])\n","    np.save(\"./temp/c3cd.npy\", array1)\n","    print(\"max is：\",np.max(array1)) \n","    plt.plot(range(100),array1,'y', label='CNN+3DCNN+DNN')\n","    plt.legend() # 展示图例\n","    plt.title(\"model F1_score\")\n","    plt.ylabel(\"F1_score\")\n","    plt.xlabel(\"epoch\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qHX8j1zNGhLt","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DRTuyP2V2n9H","colab_type":"code","colab":{}},"source":["#coding=utf-8\n","#多模态网络3  CNN+CNN+LSTM\n","from keras.utils import np_utils, generic_utils\n","from sklearn.model_selection import train_test_split\n","\n","import matplotlib.pyplot as plt\n","\n","from keras import regularizers\n","from keras.layers import *\n","from keras.layers import Input\n","from keras.models import Model\n","from keras.utils import plot_model\n","import numpy as np\n","from keras.callbacks import ReduceLROnPlateau\n","from keras import backend as K\n","gram_rows, gram_cols,gram_depth =100,128,1#resize parameters\n","\n","img_rows, img_cols,img_depth =64,64,18#resize parameters\n","# number of convolutional filters to use at each layer 每一层卷积器数量\n","nb_filters = [  16,   # 1st conv layer\n","                8   # 2nd\n","             ]\n","\n","nb_pool = [3, 3]\n","nb_classes = 2\n","\n","\n","nb_conv = [5,5]\n","\n","\n","def f1(y_true, y_pred):    #f1评价指标\n","    def recall(y_true, y_pred):\n","        \"\"\"Recall metric.\n","\n","        Only computes a batch-wise average of recall.\n","\n","        Computes the recall, a metric for multi-label classification of\n","        how many relevant items are selected.\n","        \"\"\"\n","        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n","        recall = true_positives / (possible_positives + K.epsilon())\n","        return recall\n","\n","    def precision(y_true, y_pred):\n","        \"\"\"Precision metric.\n","\n","        Only computes a batch-wise average of precision.\n","\n","        Computes the precision, a metric for multi-label classification of\n","        how many selected items are relevant.\n","        \"\"\"\n","        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n","        precision = true_positives / (predicted_positives + K.epsilon())\n","        return precision\n","    precision = precision(y_true, y_pred)\n","    recall = recall(y_true, y_pred)\n","    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n","\n","\n","\n","\n","\n","def multi_input_model():\n","    \"\"\"构建多输入模型\"\"\"\n","\n","    conv1_channel = 32\n","    input1 = Input(shape = (gram_rows,gram_cols,gram_depth),name='input1')\n","    x = Conv2D(conv1_channel, kernel_size=(5,5), activation='relu', input_shape=(gram_rows, gram_cols, gram_depth))(input1)\n","    #x = BatchNormalization(axis=3)(x)\n","    x = MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n","    x = Conv2D(8, kernel_size=(5,5), activation='relu')(x)\n","    x = MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n","    x  = (Flatten())(x)\n","    output1  = Dense(256)(x)\n","\n","    input2 = Input(shape = (gram_rows,gram_cols,gram_depth),name='input2')\n","    x = Conv2D(conv1_channel, kernel_size=(5,5), activation='relu', input_shape=(gram_rows, gram_cols, gram_depth))(input2)\n","    #x = BatchNormalization(axis=3)(x)\n","    x = MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n","    x = Conv2D(8, kernel_size=(5,5), activation='relu')(x)\n","    x = MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n","    x  = (Flatten())(x)\n","    output2  = Dense(256)(x)\n","\n","    input3 = Input(shape = (gram_rows,gram_cols,gram_depth),name='input3')\n","    x = Conv2D(conv1_channel, kernel_size=(5,5), activation='relu', input_shape=(gram_rows, gram_cols, gram_depth))(input3)\n","    #x = BatchNormalization(axis=3)(x)\n","    x = MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n","    x = Conv2D(8, kernel_size=(5,5), activation='relu')(x)\n","    x = MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n","    x  = (Flatten())(x)\n","    output3  = Dense(256)(x)\n","    \n","\n","\n","\n","\n","    input4 = Input(shape = (img_rows,img_cols*6,gram_depth),name='input4')\n","    x = Conv2D(32, kernel_size=(5,5), activation='relu', input_shape=(gram_rows, gram_cols, gram_depth))(input4)\n","    x = MaxPool2D(pool_size=(3,3), strides=(2,2))(x)\n","    x = Conv2D(8, kernel_size=(5,5), activation='relu')(x)\n","    x = MaxPool2D(pool_size=(3,3), strides=(2,2))(x)\n","    x  = (Flatten())(x)\n","    output4 = Dense(256)(x)\n","    \n","    \n","    input5 = Input(shape = (img_rows,img_cols*6,gram_depth),name='input5')\n","    x = Conv2D(32, kernel_size=(5,5), activation='relu', input_shape=(gram_rows, gram_cols, gram_depth))(input5)\n","    x = MaxPool2D(pool_size=(3,3), strides=(2,2))(x)\n","    x = Conv2D(8, kernel_size=(5,5), activation='relu')(x)\n","    x = MaxPool2D(pool_size=(3,3), strides=(2,2))(x)\n","    x  = (Flatten())(x)\n","    output5 = Dense(256)(x)\n","   \n","\n","    input6 = Input(shape = (img_rows,img_cols*6,gram_depth),name='input6')\n","    x = Conv2D(32, kernel_size=(5,5), activation='relu', input_shape=(gram_rows, gram_cols, gram_depth))(input6)\n","    x = MaxPool2D(pool_size=(3,3), strides=(2,2))(x)\n","    x = Conv2D(8, kernel_size=(5,5), activation='relu')(x)\n","    x = MaxPool2D(pool_size=(3,3), strides=(2,2))(x)\n","    x  = (Flatten())(x)\n","    output6 = Dense(256)(x)\n","\n","\n","\n","    \n","    x1 = Concatenate(axis=1)([output1,output4])\n","    print(K.int_shape(x1))\n","    \n","\n","    x2 = Concatenate(axis=1)([output2,output5])\n","    print(K.int_shape(x2)[1])\n","    x3 = Concatenate(axis=1)([output3,output6])\n","    \n","    x = Concatenate(axis=1)([x1,x2,x3])\n","    print(K.int_shape(x))\n","    #x = K.reshpae(:,3,6672)\n","    #x= Lambda(lambda x:K.expand_dims(x,axis=-1))(x)\n","    dim = K.int_shape(x1)[1]\n","    print(dim)\n","    x = Reshape((3,dim))(x)\n","    \n","    x = LSTM(units=50, input_shape=(3, dim), return_sequences=False)(x)\n","    #x= LSTM(units=50, return_sequences=False)(x)\n","    x = Dropout(0.2)(x)\n","    x =  Dense(nb_classes, kernel_regularizer = regularizers.l1(0.01), activation='softmax')(x)\n","    #x = Dense(nb_classes, activation ='softmax')(x)\n","    \n","  \n","    model = Model(inputs=[input1, input2,input3, input4,input5, input6], outputs=[x])\n","    model.summary()\n","  \n","    return model\n","\n","if __name__ == '__main__':\n","\n","  \n","    # 产生视频数据\n","    X_tr_array = np.load(\"./picture64.npy\",allow_pickle = True)\n","    num_samples = len(X_tr_array)\n","    label=np.ones((num_samples,), dtype = int)   #创建相同规格的lable\n","    #each class has 100 videos\n","    label[0:1399] = 1\n","    label[1399:] = 0\n","    y_train = label\n","    train_set = np.zeros((num_samples, img_rows, img_cols, img_depth, 1))\n","    y_train = np_utils.to_categorical(y_train, nb_classes)#将标签转化为int编码\n","    for h in range(num_samples):\n","      train_set[h,:,:,:,0]=X_tr_array[h,:,:,:]   #这里增加一维度，用来符合3D卷积网络的输入#(600, 64, 64, 18,1)\n","    train_set = train_set.astype('float32')\n","    train_set -= np.mean(train_set)\n","    train_set /= np.max(train_set)\n","    #print('X_Train shape:', train_set.shape)#(600, 32, 32, 39,1)    \n","    X_train_new, X_val_new, y_train_new,y_val_new = train_test_split(train_set, y_train, test_size=0.2, random_state=14)   # 视频的分配结束，random_state与音频保持一致\n"," \n","    X1 =  X_train_new[:,:,:,0:6,:]\n","    X1 = X1.reshape(2459,64,64*6,1)\n","    X2 =  X_train_new[:,:,:,6:12,:]\n","    X2 = X2.reshape(2459,64,64*6,1)\n","    X3 =  X_train_new[:,:,:,12:18,:]\n","    X3 = X3.reshape(2459,64,64*6,1)\n","    Y1 =  X_val_new[:,:,:,0:6,:]\n","    Y1 = Y1.reshape(615,64,64*6,1)\n","    Y2 =  X_val_new[:,:,:,6:12,:]\n","    Y2 = Y2.reshape(615,64,64*6,1)\n","    Y3 =  X_val_new[:,:,:,12:18,:]\n","    Y3 = Y3.reshape(615,64,64*6,1)\n","    #print(X1.shape)\n","\n","\n","#音频数据处理\n","    X = np.load('datagram3s.npy',allow_pickle = True)\n","    y = np.load('targetgram3s.npy',allow_pickle = True)\n","    X = X.astype('float32')\n","    X -= np.mean(X)\n","    X /= np.max(X)\n","    X = X.reshape(X.shape[0], 300, 128, 1)\n","    #print('X_Train shape:', X.shape)#(600, 32, 32, 39,1) \n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=14)\n","                                                    \n","    X4 =  X_train[:,0:100,:,:]  #将300*128的语谱图分成3个100ms的128维度语谱图图像，与视频6帧对应\n","    X5 =  X_train[:,100:200,:,:]\n","    X6 =  X_train[:,200:300,:,:]\n","    Y4 =  X_test[:,0:100,:,:]\n","    Y5 =  X_test[:,100:200,:,:]\n","    Y6 =  X_test[:,200:300,:,:]\n","    model = multi_input_model()\n","    model.summary()\n"," \n","    plot_model(model, 'Multi_input_model.png')\n","    reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=10, mode='auto')\n","    model.compile(optimizer='RMSprop', loss='binary_crossentropy', metrics=[f1])#f1分数评价\n","    history = model.fit([X4,X5,X6,X1,X2,X3], y_train_new, epochs=100,validation_data=([Y4,Y5,Y6,Y1,Y2,Y3], y_val_new), batch_size=32,shuffle=True, callbacks=[reduce_lr])#训练\n","\n","    model.save('ccl.h5')\n","    array1=np.array(history.history['val_f1'])\n","    np.save(\"./temp/ccl.npy\", array1)\n","    print(\"max is：\",np.max(array1)) \n","    plt.plot(range(100),array1,'y', label='CNN+CNN+LSTM')\n","    plt.legend() # 展示图例\n","    plt.title(\"model F1_score\")\n","    plt.ylabel(\"F1_score\")\n","    plt.xlabel(\"epoch\")\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Os7xTWNkXADd","colab_type":"code","colab":{}},"source":["#coding=utf-8\n","#多模态网络3  CNN+3DCNN+LSTM\n","from keras.utils import np_utils, generic_utils\n","from sklearn.model_selection import train_test_split\n","\n","import matplotlib.pyplot as plt\n","\n","from keras import regularizers\n","from keras.layers import *\n","from keras.layers import Input\n","from keras.models import Model\n","from keras.utils import plot_model\n","import numpy as np\n","from keras.callbacks import ReduceLROnPlateau\n","from keras import backend as K\n","gram_rows, gram_cols,gram_depth =100,128,1#resize parameters\n","\n","img_rows, img_cols,img_depth =64,64,18#resize parameters\n","# number of convolutional filters to use at each layer 每一层卷积器数量\n","nb_filters = [  16,   # 1st conv layer\n","                8   # 2nd\n","             ]\n","\n","nb_pool = [3, 3]\n","nb_classes = 2\n","\n","\n","nb_conv = [5,5]\n","\n","\n","def f1(y_true, y_pred):    #f1评价指标\n","    def recall(y_true, y_pred):\n","        \"\"\"Recall metric.\n","\n","        Only computes a batch-wise average of recall.\n","\n","        Computes the recall, a metric for multi-label classification of\n","        how many relevant items are selected.\n","        \"\"\"\n","        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n","        recall = true_positives / (possible_positives + K.epsilon())\n","        return recall\n","\n","    def precision(y_true, y_pred):\n","        \"\"\"Precision metric.\n","\n","        Only computes a batch-wise average of precision.\n","\n","        Computes the precision, a metric for multi-label classification of\n","        how many selected items are relevant.\n","        \"\"\"\n","        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n","        precision = true_positives / (predicted_positives + K.epsilon())\n","        return precision\n","    precision = precision(y_true, y_pred)\n","    recall = recall(y_true, y_pred)\n","    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n","\n","\n","\n","\n","\n","def multi_input_model():\n","    \"\"\"构建多输入模型\"\"\"\n","\n","    conv1_channel = 32\n","    input1 = Input(shape = (gram_rows,gram_cols,gram_depth),name='input1')\n","    x = Conv2D(conv1_channel, kernel_size=(5,5), activation='relu', input_shape=(gram_rows, gram_cols, gram_depth))(input1)\n","    #x = BatchNormalization(axis=3)(x)\n","    x = MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n","    x = Conv2D(8, kernel_size=(5,5), activation='relu')(x)\n","    x = MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n","    output1 = (Flatten())(x)\n","\n","    input2 = Input(shape = (gram_rows,gram_cols,gram_depth),name='input2')\n","    x = Conv2D(conv1_channel, kernel_size=(5,5), activation='relu', input_shape=(gram_rows, gram_cols, gram_depth))(input2)\n","    #x = BatchNormalization(axis=3)(x)\n","    x = MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n","    x = Conv2D(8, kernel_size=(5,5), activation='relu')(x)\n","    x = MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n","    output2 = (Flatten())(x)\n","\n","    input3 = Input(shape = (gram_rows,gram_cols,gram_depth),name='input3')\n","    x = Conv2D(conv1_channel, kernel_size=(5,5), activation='relu', input_shape=(gram_rows, gram_cols, gram_depth))(input3)\n","    #x = BatchNormalization(axis=3)(x)\n","    x = MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n","    x = Conv2D(8, kernel_size=(5,5), activation='relu')(x)\n","    x = MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n","    output3 = (Flatten())(x)\n","\n","\n","\n","\n","    input4 = Input(shape = (img_rows,img_cols,6,1), name='input4')\n","    x = Convolution3D(nb_filters[0],(5,5,2),input_shape=(img_rows, img_cols,img_depth,1),activation='relu')(input4)\n","    x = MaxPooling3D(pool_size=(2, 2, 2))(x)\n","    x = Convolution3D(nb_filters[1],(3,3,1),activation='relu')(x)\n","    x = MaxPooling3D(pool_size=(2, 2, 2))(x)\n","    output4 = (Flatten())(x)\n","  \n","    input5 = Input(shape = (img_rows,img_cols,6,1), name='input5')\n","    x = Convolution3D(nb_filters[0],(5,5,2),input_shape=(img_rows, img_cols,img_depth,1),activation='relu')(input5)\n","    x = MaxPooling3D(pool_size=(2, 2, 2))(x)\n","    x = Convolution3D(nb_filters[1],(3,3,1),activation='relu')(x)\n","    x = MaxPooling3D(pool_size=(2, 2, 2))(x)\n","    output5 = (Flatten())(x)\n","\n","    input6 = Input(shape = (img_rows,img_cols,6,1), name='input6')\n","    x = Convolution3D(nb_filters[0],(5,5,2),input_shape=(img_rows, img_cols,img_depth,1),activation='relu')(input6)\n","    x = MaxPooling3D(pool_size=(2, 2, 2))(x)\n","    x = Convolution3D(nb_filters[1],(3,3,1),activation='relu')(x)\n","    x = MaxPooling3D(pool_size=(2, 2, 2))(x)\n","    output6 = (Flatten())(x)\n","\n","\n","\n","    \n","    x1 = Concatenate(axis=1)([output1,output4])\n","    print(K.int_shape(x1))\n","    \n","\n","    x2 = Concatenate(axis=1)([output2,output5])\n","    print(K.int_shape(x2)[1])\n","    x3 = Concatenate(axis=1)([output3,output6])\n","    \n","    x = Concatenate(axis=1)([x1,x2,x3])\n","    print(K.int_shape(x))\n","    #x = K.reshpae(:,3,6672)\n","    #x= Lambda(lambda x:K.expand_dims(x,axis=-1))(x)\n","    dim = K.int_shape(x1)[1]\n","    print(dim)\n","    x = Reshape((3,dim))(x)\n","    \n","    x = LSTM(units=50, input_shape=(3, dim), return_sequences=False)(x)\n","    #x= LSTM(units=50, return_sequences=False)(x)\n","    x = Dropout(0.2)(x)\n","    x =  Dense(nb_classes, kernel_regularizer = regularizers.l1(0.01), activation='softmax')(x)\n","    #x = Dense(nb_classes, activation ='softmax')(x)\n","    \n","  \n","    model = Model(inputs=[input1, input2,input3, input4,input5, input6], outputs=[x])\n","    model.summary()\n","  \n","    return model\n","\n","if __name__ == '__main__':\n","\n","  \n","    # 产生视频数据\n","    X_tr_array = np.load(\"./picture64.npy\",allow_pickle = True)\n","    num_samples = len(X_tr_array)\n","    label=np.ones((num_samples,), dtype = int)   #创建相同规格的lable\n","    #each class has 100 videos\n","    label[0:1399] = 1\n","    label[1399:] = 0\n","    y_train = label\n","    train_set = np.zeros((num_samples, img_rows, img_cols, img_depth, 1))\n","    y_train = np_utils.to_categorical(y_train, nb_classes)#将标签转化为int编码\n","    for h in range(num_samples):\n","      train_set[h,:,:,:,0]=X_tr_array[h,:,:,:]   #这里增加一维度，用来符合3D卷积网络的输入#(600, 64, 64, 18,1)\n","    train_set = train_set.astype('float32')\n","    train_set -= np.mean(train_set)\n","    train_set /= np.max(train_set)\n","    #print('X_Train shape:', train_set.shape)#(600, 32, 32, 39,1)    \n","    X_train_new, X_val_new, y_train_new,y_val_new = train_test_split(train_set, y_train, test_size=0.2, random_state=14)   # 视频的分配结束，random_state与音频保持一致\n","    X1 =  X_train_new[:,:,:,0:6,:]   #将每个视频的18帧变成三份6帧的\n","    X2 =  X_train_new[:,:,:,6:12,:]\n","    X3 =  X_train_new[:,:,:,12:18,:]\n","    Y1 =  X_val_new[:,:,:,0:6,:]    #目标\n","    Y2 =  X_val_new[:,:,:,6:12,:]\n","    Y3 =  X_val_new[:,:,:,12:18,:]\n","    #print(X1.shape)\n","\n","\n","#音频数据处理\n","    X = np.load('datagram3s.npy',allow_pickle = True)\n","    y = np.load('targetgram3s.npy',allow_pickle = True)\n","    X = X.astype('float32')\n","    X -= np.mean(X)\n","    X /= np.max(X)\n","    X = X.reshape(X.shape[0], 300, 128, 1)\n","    #print('X_Train shape:', X.shape)#(600, 32, 32, 39,1) \n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=14)\n","                                                    \n","    X4 =  X_train[:,0:100,:,:]  #将300*128的语谱图分成3个100ms的128维度语谱图图像，与视频6帧对应\n","    X5 =  X_train[:,100:200,:,:]\n","    X6 =  X_train[:,200:300,:,:]\n","    Y4 =  X_test[:,0:100,:,:]\n","    Y5 =  X_test[:,100:200,:,:]\n","    Y6 =  X_test[:,200:300,:,:]\n","    model = multi_input_model()\n","    model.summary()\n"," \n","    plot_model(model, 'Multi_input_model.png')\n","    reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=10, mode='auto')\n","    model.compile(optimizer='RMSprop', loss='binary_crossentropy', metrics=[f1])#f1分数评价\n","    history = model.fit([X4,X5,X6,X1,X2,X3], y_train_new, epochs=100,validation_data=([Y4,Y5,Y6,Y1,Y2,Y3], y_val_new), batch_size=32,shuffle=True, callbacks=[reduce_lr])#训练\n","\n","    model.save('c3dl.h5')\n","    array1=np.array(history.history['val_f1'])\n","    np.save(\"./temp/c3dl.npy\", array1)\n","    print(\"max is：\",np.max(array1)) \n","    plt.plot(range(100),array1,'y', label='CNN+3DCNN+LSTM')\n","    plt.legend() # 展示图例\n","    plt.title(\"model F1_score\")\n","    plt.ylabel(\"F1_score\")\n","    plt.xlabel(\"epoch\")\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"q3tVaI1IAWJ4","colab_type":"code","colab":{}},"source":["#画图\n","\n","import numpy as np\n","import matplotlib.pylab as plt\n","\n","def drawOne():\n","  x1 = np.load('./temp/cnn2.npy',allow_pickle = True)\n","  x2 = np.load('./temp/cnn4.npy',allow_pickle = True)\n","  x3 = np.load('./temp/cnn6.npy',allow_pickle = True)\n","  x4 = np.load('./temp/3DCNN.npy',allow_pickle = True)\n","  x5 = np.load('./temp/LSTM.npy',allow_pickle = True)\n","  x6 = np.linspace(0.843,0.843,100)\n","  plt.plot(range(100),x6,'g', label='SVM')\n","  plt.plot(range(100),x3,'r', label='CNN6', linewidth=2, linestyle='dashdot')\n","  \n","  plt.plot(range(100),x4,'black', label='3DCNN', linewidth=2, linestyle=\"-\")\n","  plt.plot(range(100),x5,'b', label='LSTM',linewidth=2, linestyle=\"--\")\n","  \n","  plt.legend() # 展示图例\n","  plt.title(\"model F1_score\")\n","  plt.ylabel(\"F1_score\")\n","  plt.xlabel(\"epoch\")\n","  plt.savefig(\"drawOne.jpg\")\n","def drwaTwo():\n","  x1 = np.load('./temp/LSTM.npy',allow_pickle = True)\n","  x2 = np.load('./temp/ccd.npy',allow_pickle = True)\n","  x3 = np.load('./temp/c3cd.npy',allow_pickle = True)\n","  x4 = np.load('./temp/c3dl.npy',allow_pickle = True)\n","  x5 = np.load('./temp/ccl.npy',allow_pickle = True)\n","\n","  plt.plot(range(100),x1,'r', label='LSTM', linewidth=2, linestyle='dashdot')\n","  \n","  plt.plot(range(100),x2,'c', label='CNN+CNN+FC', linewidth=2, linestyle=\"dotted\")\n","  plt.plot(range(100),x3,'b', label='CNN+3DCNN+FC',linewidth=2, linestyle=\":\")\n","  plt.plot(range(100),x5,'g', label='CNN+CNN+LSTM',linewidth=2, linestyle=\"-\")\n","  plt.plot(range(100),x4,'black', label='CNN+3DCNN+LSTM')\n","  \n","  plt.legend() # 展示图例\n","  plt.title(\"model F1_score\")\n","  plt.ylabel(\"F1_score\")\n","  plt.xlabel(\"epoch\")\n","  plt.savefig(\"drawTwo.jpg\")\n","\n","if __name__ == '__main__':\n","  #drawOne()\n","  drwaTwo()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bHgibcHYIttF","colab_type":"code","colab":{}},"source":["#画图\n","\n","import numpy as np\n","import matplotlib.pylab as plt\n","\n","def drawOne():\n","  x1 = np.load('./temp/cnn2.npy',allow_pickle = True)\n","  x2 = np.load('./temp/cnn4.npy',allow_pickle = True)\n","  x3 = np.load('./temp/cnn6.npy',allow_pickle = True)\n","  x4 = np.load('./temp/3DCNN.npy',allow_pickle = True)\n","  x5 = np.load('./temp/LSTM.npy',allow_pickle = True)\n","  data1 = data = [32,64,128,256,512]\n","  data = [0.795,0.811,0.813,0.821,0.819]\n","  x6 = np.array(data)\n","\n","  plt.plot(data1,x6,'b')\n","  #plt.plot(range(100),x3,'r', label='CNN6', linewidth=2, linestyle='dashdot')\n","  \n","  #plt.plot(range(100),x4,'black', label='3DCNN', linewidth=2, linestyle=\"-\")\n","  #plt.plot(range(100),x5,'b', label='LSTM',linewidth=2, linestyle=\"--\")\n","  \n","  plt.legend() # 展示图例\n","  plt.title(\"model acc\")\n","  plt.ylabel(\"acc\")\n","  plt.xlabel(\"epoch\")\n","  plt.savefig(\"drawOne.jpg\")\n","def drwaTwo():\n","  x1 = np.load('./temp/LSTM.npy',allow_pickle = True)\n","  x2 = np.load('./temp/ccd.npy',allow_pickle = True)\n","  x3 = np.load('./temp/c3cd.npy',allow_pickle = True)\n","  x3 = np.load('./temp/cnn6.npy',allow_pickle = True)\n","  x4 = np.load('./temp/c3dl.npy',allow_pickle = True)\n","  x5 = np.load('./temp/ccl.npy',allow_pickle = True)\n","\n","  plt.plot(range(100),x1,'r', label='SGD', linewidth=2, linestyle='dashdot')\n","  \n","  plt.plot(range(100),x3,'black', label='RMspop', linewidth=2, linestyle=\"dotted\")\n","  plt.plot(range(100),x2,'b', label='adam',linewidth=2)\n","  # plt.plot(range(100),x5,'g', label='CNN+CNN+LSTM',linewidth=2, linestyle=\"-\")\n","  # plt.plot(range(100),x4,'black')\n","  \n","  plt.legend() # 展示图例\n","  plt.title(\"model acc\")\n","  plt.ylabel(\"acc\")\n","  plt.xlabel(\"epoch\")\n","  plt.savefig(\"drawTwo.jpg\")\n","\n","if __name__ == '__main__':\n","  drawOne()\n","  #drwaTwo()"],"execution_count":0,"outputs":[]}]}